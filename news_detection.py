# -*- coding: utf-8 -*-
"""news detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11pDg2d2cNyqiHxGMhGtzIbNgQ441Gmkp
"""

# simple_fake_news.py
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# 1. Tiny dataset (you can replace with real CSV later)
texts = [
    "Breaking! You won a lottery, click here to claim.",       # fake
    "Government releases new economic policy report.",          # real
    "Shocking! Cure for all diseases found in this herb!",      # fake
    "Local university ranked among top in the country.",        # real
    "Scientists confirm aliens landed in desert.",              # fake
    "New tax reforms announced by finance minister."            # real
]
labels = ["fake", "real", "fake", "real", "fake", "real"]

# 2. Train/test split
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)

# 3. TF-IDF + Logistic Regression
vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

clf = LogisticRegression()
clf.fit(X_train_vec, y_train)

# 4. Predictions
y_pred = clf.predict(X_test_vec)

# 5. Results
print("Classification Report:\n", classification_report(y_test, y_pred))

# 6. Try new examples
samples = [
    "Breaking news: Prime Minister visits flood-affected areas.",
    "Win a free iPhone by clicking this special link!"
]
preds = clf.predict(vectorizer.transform(samples))
for text, label in zip(samples, preds):
    print(f"\nText: {text}\nPredicted Label: {label}")

